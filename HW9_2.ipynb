{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Домашнее задание\n",
    "\n",
    "Нужно реализовать rest api на базе flask (пример https://github.com/fimochka-sudo/GB_docker_flask_example)\n",
    "\n",
    "По шагам:\n",
    "0. выбрать себе датасет (который интересен или нравится больше всего), сделать pipeline (преобразования + модель), сохранить его на диск. Если не хочется пайплайн, то можно без него, но так вам же будет удобнее потом вызывать его из кода сервиса.\n",
    "1. установить удобную для себя среду разработки (pycharm прекрасен - https://www.jetbrains.com/pycharm/)\n",
    "2. для вашего проекта вам понадобится requirements.txt с пакетами. Можно за основу взять такой файл из проекта выше. Для его установки прям в pycharm можно открыть терминал и сделать pip install -r requirements.txt (находясь в корне проекта конечно же при этом)\n",
    "3. завести себе аккаунт на github (если его еще нет). У самого github есть такой \"hello world\" по работе с ним - https://guides.github.com/activities/hello-world/\n",
    "4. итоговый проект должен содержать: 1) каталог app/models/ (здесь модель-пайплайн предобученная либо код обучения модели-пайплайна) 2) файл app/run_server.py (здесь основной код flask-приложения) 3) requirements.txt (список пакетов, которые у вас используются в проекте - в корне проекта) 4) README.md (здесь какое-то описание, что вы делаете, что за данные, как запускать и т.д) 5) Dockerfile 6) docker-entrypoint.sh\n",
    "5. (<b>Опционально</b>): front-end сервис какой-то, который умеет принимать от пользователя введеные данные и ходить в ваш api. На самом деле полезно больше вам, т.к если ваш проект будет далее развиваться (новые модели, интересные подходы), то это хороший пунктик к резюме и в принципе - строчка в портфолио)\n",
    "\n",
    "Полезные ссылки:\n",
    "1. датасеты (для полета мысли): https://www.kaggle.com/datasets\n",
    "2. конкурс Сбербанка по недвижимости (можно этот набор данных также взять и обучить модель предсказывать стоимость жилья - неплохой такой сервис может получиться) - https://www.kaggle.com/c/sberbank-russian-housing-market/data Там же и ноутбуки с разными подходами есть.\n",
    "3. минималистичный пример связки keras/flask https://blog.keras.io/building-a-simple-keras-deep-learning-rest-api.html для определения класса картинки\n",
    "4. неплохой такой пример (помимо того, что разобрали на занятии) связки docker/flask - https://cloud.croc.ru/blog/byt-v-teme/flask-prilozheniya-v-docker/\n",
    "5. https://www.digitalocean.com/community/tutorials/how-to-build-and-deploy-a-flask-application-using-docker-on-ubuntu-18-04\n",
    "\n",
    "p.s. если проблемы с выбором датасета, то пишите пожалуйста - будем вместе думать)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Step 1 - TRAIN\n",
    "\n",
    "### Обучение пайплайна\n",
    "\n",
    "1. Загрузим данные https://www.kaggle.com/competitions/titanic\n",
    "2. Соберем пайплайн с простейшим препроцессингом (tfidf) на текстовых данных\n",
    "3. Обучим логистическую регрессию и сохраним на диск предобученный пайплайн"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import dill\n",
    "import numpy as np\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.base import BaseEstimator, TransformerMixin\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.metrics import confusion_matrix, accuracy_score, classification_report\n",
    "from sklearn.metrics import roc_auc_score, roc_curve, precision_recall_curve\n",
    "from sklearn.metrics import f1_score\n",
    "\n",
    "#working with text\n",
    "from sklearn.feature_extraction.text import TfidfVectorizer\n",
    "\n",
    "#normalizing data\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "\n",
    "#pipeline\n",
    "from sklearn.pipeline import Pipeline, FeatureUnion\n",
    "from sklearn.metrics import precision_score,recall_score\n",
    "\n",
    "#imputer\n",
    "from sklearn.impute import SimpleImputer\n",
    "\n",
    "import sklearn.datasets\n",
    "\n",
    "%matplotlib inline\n",
    "import matplotlib.pylab as plt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Создание маленькой выборки для отладки кода\n",
    "\n",
    "#df = pd.read_csv(\"train.csv\")\n",
    "#df1 = df.sample(n=90000, random_state=1)\n",
    "#df1.to_csv(\"train_mini.csv\", index=None)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>PassengerId</th>\n",
       "      <th>Survived</th>\n",
       "      <th>Pclass</th>\n",
       "      <th>Name</th>\n",
       "      <th>Sex</th>\n",
       "      <th>Age</th>\n",
       "      <th>SibSp</th>\n",
       "      <th>Parch</th>\n",
       "      <th>Ticket</th>\n",
       "      <th>Fare</th>\n",
       "      <th>Cabin</th>\n",
       "      <th>Embarked</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>3</td>\n",
       "      <td>Braund, Mr. Owen Harris</td>\n",
       "      <td>male</td>\n",
       "      <td>22.0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>A/5 21171</td>\n",
       "      <td>7.2500</td>\n",
       "      <td>NaN</td>\n",
       "      <td>S</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>Cumings, Mrs. John Bradley (Florence Briggs Th...</td>\n",
       "      <td>female</td>\n",
       "      <td>38.0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>PC 17599</td>\n",
       "      <td>71.2833</td>\n",
       "      <td>C85</td>\n",
       "      <td>C</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>3</td>\n",
       "      <td>1</td>\n",
       "      <td>3</td>\n",
       "      <td>Heikkinen, Miss. Laina</td>\n",
       "      <td>female</td>\n",
       "      <td>26.0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>STON/O2. 3101282</td>\n",
       "      <td>7.9250</td>\n",
       "      <td>NaN</td>\n",
       "      <td>S</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   PassengerId  Survived  Pclass  \\\n",
       "0            1         0       3   \n",
       "1            2         1       1   \n",
       "2            3         1       3   \n",
       "\n",
       "                                                Name     Sex   Age  SibSp  \\\n",
       "0                            Braund, Mr. Owen Harris    male  22.0      1   \n",
       "1  Cumings, Mrs. John Bradley (Florence Briggs Th...  female  38.0      1   \n",
       "2                             Heikkinen, Miss. Laina  female  26.0      0   \n",
       "\n",
       "   Parch            Ticket     Fare Cabin Embarked  \n",
       "0      0         A/5 21171   7.2500   NaN        S  \n",
       "1      0          PC 17599  71.2833   C85        C  \n",
       "2      0  STON/O2. 3101282   7.9250   NaN        S  "
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Загрузим данные\n",
    "\n",
    "df = pd.read_csv(\"train.csv\")\n",
    "df.head(3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0    549\n",
       "1    342\n",
       "Name: Survived, dtype: int64"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#Выясним количество классов\n",
    "\n",
    "df['Survived'].value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#Определим дубликаты\n",
    "\n",
    "df.duplicated().sum()\n",
    "\n",
    "#Дубликатов нет"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "#df['Age'] = df['Age'].fillna(df.Age.mode()[0])\n",
    "#df['Cabin'] = df['Cabin'].fillna('Unknown')\n",
    "#df['Embarked'] = df['Embarked'].fillna(df.Embarked.mode()[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "6      0\n",
       "718    0\n",
       "685    0\n",
       "73     0\n",
       "882    0\n",
       "      ..\n",
       "106    1\n",
       "270    0\n",
       "860    0\n",
       "435    1\n",
       "102    0\n",
       "Name: Survived, Length: 596, dtype: int64"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#Разделим данные на train/test и сохраним тестовую выборку на диск\n",
    "\n",
    "X_train, X_test, y_train, y_test = train_test_split(df.drop('Survived', 1), df['Survived'],\n",
    "                                                    test_size=0.33, random_state=42)\n",
    "# save test\n",
    "X_test.to_csv(\"X_test.csv\", index=None)\n",
    "y_test.to_csv(\"y_test.csv\", index=None)\n",
    "\n",
    "# save train\n",
    "X_train.to_csv(\"X_train.csv\", index=None)\n",
    "y_train.to_csv(\"y_train.csv\", index=None)\n",
    "y_train"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "PassengerId      int64\n",
       "Pclass           int64\n",
       "Name            object\n",
       "Sex             object\n",
       "Age            float64\n",
       "SibSp            int64\n",
       "Parch            int64\n",
       "Ticket          object\n",
       "Fare           float64\n",
       "Cabin           object\n",
       "Embarked        object\n",
       "dtype: object"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#Проанализируем данные\n",
    "\n",
    "X_train.dtypes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>PassengerId</th>\n",
       "      <th>Pclass</th>\n",
       "      <th>Age</th>\n",
       "      <th>SibSp</th>\n",
       "      <th>Parch</th>\n",
       "      <th>Fare</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>count</th>\n",
       "      <td>596.000000</td>\n",
       "      <td>596.000000</td>\n",
       "      <td>478.000000</td>\n",
       "      <td>596.000000</td>\n",
       "      <td>596.000000</td>\n",
       "      <td>596.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>mean</th>\n",
       "      <td>448.508389</td>\n",
       "      <td>2.337248</td>\n",
       "      <td>29.525983</td>\n",
       "      <td>0.577181</td>\n",
       "      <td>0.374161</td>\n",
       "      <td>31.912786</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>std</th>\n",
       "      <td>259.457226</td>\n",
       "      <td>0.823207</td>\n",
       "      <td>14.457437</td>\n",
       "      <td>1.229504</td>\n",
       "      <td>0.807072</td>\n",
       "      <td>51.480961</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>min</th>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.420000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>25%</th>\n",
       "      <td>221.750000</td>\n",
       "      <td>2.000000</td>\n",
       "      <td>20.250000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>7.925000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>50%</th>\n",
       "      <td>459.500000</td>\n",
       "      <td>3.000000</td>\n",
       "      <td>28.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>14.454200</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>75%</th>\n",
       "      <td>676.250000</td>\n",
       "      <td>3.000000</td>\n",
       "      <td>38.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>31.275000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>max</th>\n",
       "      <td>891.000000</td>\n",
       "      <td>3.000000</td>\n",
       "      <td>80.000000</td>\n",
       "      <td>8.000000</td>\n",
       "      <td>6.000000</td>\n",
       "      <td>512.329200</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "       PassengerId      Pclass         Age       SibSp       Parch        Fare\n",
       "count   596.000000  596.000000  478.000000  596.000000  596.000000  596.000000\n",
       "mean    448.508389    2.337248   29.525983    0.577181    0.374161   31.912786\n",
       "std     259.457226    0.823207   14.457437    1.229504    0.807072   51.480961\n",
       "min       1.000000    1.000000    0.420000    0.000000    0.000000    0.000000\n",
       "25%     221.750000    2.000000   20.250000    0.000000    0.000000    7.925000\n",
       "50%     459.500000    3.000000   28.000000    0.000000    0.000000   14.454200\n",
       "75%     676.250000    3.000000   38.000000    1.000000    0.000000   31.275000\n",
       "max     891.000000    3.000000   80.000000    8.000000    6.000000  512.329200"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#Посмотрим выбросы по координатам\n",
    "\n",
    "X_train.describe()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "Int64Index: 596 entries, 6 to 102\n",
      "Data columns (total 11 columns):\n",
      " #   Column       Non-Null Count  Dtype  \n",
      "---  ------       --------------  -----  \n",
      " 0   PassengerId  596 non-null    int64  \n",
      " 1   Pclass       596 non-null    int64  \n",
      " 2   Name         596 non-null    object \n",
      " 3   Sex          596 non-null    object \n",
      " 4   Age          478 non-null    float64\n",
      " 5   SibSp        596 non-null    int64  \n",
      " 6   Parch        596 non-null    int64  \n",
      " 7   Ticket       596 non-null    object \n",
      " 8   Fare         596 non-null    float64\n",
      " 9   Cabin        134 non-null    object \n",
      " 10  Embarked     595 non-null    object \n",
      "dtypes: float64(2), int64(4), object(5)\n",
      "memory usage: 55.9+ KB\n"
     ]
    }
   ],
   "source": [
    "#Проверим датасет на наличие пустых значений\n",
    "\n",
    "X_train.info()\n",
    "\n",
    "#Пустых значений нет"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Age заменяем (Pclass=3)+(Sex=male)\n",
    "#Cabin заменяем (Pclass=1)+(Fare=mode)+(Embarked=B%)\n",
    "#Embarked заменяем (Pclass=1)+(Fare=80)+(Cabin=B%)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "# соберем наш простой pipeline, но нам понадобится написать класс для выбора нужного поля\n",
    "\n",
    "class FeatureSelector(BaseEstimator, TransformerMixin):\n",
    "    def __init__(self, column):\n",
    "        self.column = column\n",
    "\n",
    "    def fit(self, X, y=None):\n",
    "        return self\n",
    "\n",
    "    def transform(self, X, y=None):\n",
    "        return X[self.column]\n",
    "    \n",
    "    \n",
    "class NumberSelector(BaseEstimator, TransformerMixin):\n",
    "    def __init__(self, key):\n",
    "        self.key = key\n",
    "\n",
    "    def fit(self, X, y=None):\n",
    "        return self\n",
    "\n",
    "    def transform(self, X):\n",
    "        if self.key == 'Cabin':\n",
    "            X[self.key] = X[self.key].fillna('Unknown')\n",
    "        X[self.key] = X[self.key].fillna(X[self.key].mode()[0])\n",
    "        return X[[self.key]]\n",
    "    \n",
    "\n",
    "class OHEEncoder(BaseEstimator, TransformerMixin):\n",
    "    def __init__(self, key):\n",
    "        self.key = key\n",
    "        self.columns = []\n",
    "\n",
    "    def fit(self, X, y=None):\n",
    "        self.columns = [col for col in pd.get_dummies(X, prefix=self.key).columns]\n",
    "        return self\n",
    "\n",
    "    def transform(self, X):\n",
    "        X = pd.get_dummies(X, prefix=self.key)\n",
    "        test_columns = [col for col in X.columns]\n",
    "        for col_ in self.columns:\n",
    "            if col_ not in test_columns:\n",
    "                X[col_] = 0\n",
    "        return X[self.columns]\n",
    "    \n",
    "\n",
    "class TextImputer(BaseEstimator, TransformerMixin):\n",
    "    def __init__(self, key, value):\n",
    "        self.key = key\n",
    "        self.value = value\n",
    "    \n",
    "    def fit(self, X, y=None):\n",
    "        return self\n",
    "    \n",
    "    def transform(self, X):\n",
    "        X[self.key] = X[self.key].fillna(self.value)\n",
    "        return X"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Определим признаки и цели\n",
    "#Зададим списки признаков\n",
    "#['Pclass', 'Sex', 'Age', 'SibSp', 'Parch', 'Fare', 'Cabin', 'Embarked']\n",
    "\n",
    "categorical_columns = ['Sex', 'Cabin', 'Embarked']\n",
    "continuous_columns = ['Pclass', 'Age', 'SibSp', 'Parch', 'Fare']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Создадим трансформеры под каждый признак\n",
    "\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "\n",
    "final_transformers = list()\n",
    "\n",
    "for cat_col in categorical_columns:\n",
    "    cat_transformer = Pipeline([\n",
    "                ('selector', FeatureSelector(column=cat_col)),\n",
    "                ('ohe', OHEEncoder(key=cat_col))\n",
    "            ])\n",
    "    final_transformers.append((cat_col, cat_transformer))\n",
    "    \n",
    "for cont_col in continuous_columns:\n",
    "    cont_transformer = Pipeline([\n",
    "                ('selector', NumberSelector(key=cont_col)),\n",
    "                ('standard', StandardScaler())\n",
    "            ])\n",
    "    final_transformers.append((cont_col, cont_transformer))\n",
    "    \n",
    "#for text_col in text_columns:\n",
    "#    text_transformer = Pipeline([\n",
    "#                ('imputer', TextImputer(text_col, '')),\n",
    "#                ('selector', FeatureSelector(column=text_col)),\n",
    "#                ('tfidf', TfidfVectorizer())\n",
    "#            ])\n",
    "#    final_transformers.append((text_col, text_transformer))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Объединим в пайплайн\n",
    "\n",
    "from sklearn.pipeline import FeatureUnion\n",
    "\n",
    "feats = FeatureUnion(final_transformers)\n",
    "feature_processing = Pipeline([('feats', feats)])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Wall time: 2.67 s\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "Pipeline(steps=[('features',\n",
       "                 FeatureUnion(transformer_list=[('Sex',\n",
       "                                                 Pipeline(steps=[('selector',\n",
       "                                                                  FeatureSelector(column='Sex')),\n",
       "                                                                 ('ohe',\n",
       "                                                                  OHEEncoder(key='Sex'))])),\n",
       "                                                ('Cabin',\n",
       "                                                 Pipeline(steps=[('selector',\n",
       "                                                                  FeatureSelector(column='Cabin')),\n",
       "                                                                 ('ohe',\n",
       "                                                                  OHEEncoder(key='Cabin'))])),\n",
       "                                                ('Embarked',\n",
       "                                                 Pipeline(steps=[('selector',\n",
       "                                                                  FeatureSelector(column='Embarked')),\n",
       "                                                                 ('ohe',\n",
       "                                                                  OHEE...\n",
       "                                                 Pipeline(steps=[('selector',\n",
       "                                                                  NumberSelector(key='SibSp')),\n",
       "                                                                 ('standard',\n",
       "                                                                  StandardScaler())])),\n",
       "                                                ('Parch',\n",
       "                                                 Pipeline(steps=[('selector',\n",
       "                                                                  NumberSelector(key='Parch')),\n",
       "                                                                 ('standard',\n",
       "                                                                  StandardScaler())])),\n",
       "                                                ('Fare',\n",
       "                                                 Pipeline(steps=[('selector',\n",
       "                                                                  NumberSelector(key='Fare')),\n",
       "                                                                 ('standard',\n",
       "                                                                  StandardScaler())]))])),\n",
       "                ('classifier',\n",
       "                 LogisticRegression(multi_class='ovr', n_jobs=-1))])"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "%%time\n",
    "\n",
    "pipeline = Pipeline([\n",
    "    ('features', feats),\n",
    "    ('classifier', LogisticRegression(multi_class='ovr', n_jobs=-1)),   \n",
    "])\n",
    "\n",
    "pipeline.fit(X_train, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "with open(\"logreg_pipeline.dill\", \"wb\") as f:\n",
    "    dill.dump(pipeline, f)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Step 2 - PREDICT\n",
    "### Проверка работоспособности и качества пайплайна"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>PassengerId</th>\n",
       "      <th>Pclass</th>\n",
       "      <th>Name</th>\n",
       "      <th>Sex</th>\n",
       "      <th>Age</th>\n",
       "      <th>SibSp</th>\n",
       "      <th>Parch</th>\n",
       "      <th>Ticket</th>\n",
       "      <th>Fare</th>\n",
       "      <th>Cabin</th>\n",
       "      <th>Embarked</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>710</td>\n",
       "      <td>3</td>\n",
       "      <td>Moubarek, Master. Halim Gonios (\"William George\")</td>\n",
       "      <td>male</td>\n",
       "      <td>NaN</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>2661</td>\n",
       "      <td>15.2458</td>\n",
       "      <td>NaN</td>\n",
       "      <td>C</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>440</td>\n",
       "      <td>2</td>\n",
       "      <td>Kvillner, Mr. Johan Henrik Johannesson</td>\n",
       "      <td>male</td>\n",
       "      <td>31.0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>C.A. 18723</td>\n",
       "      <td>10.5000</td>\n",
       "      <td>NaN</td>\n",
       "      <td>S</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>841</td>\n",
       "      <td>3</td>\n",
       "      <td>Alhomaki, Mr. Ilmari Rudolf</td>\n",
       "      <td>male</td>\n",
       "      <td>20.0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>SOTON/O2 3101287</td>\n",
       "      <td>7.9250</td>\n",
       "      <td>NaN</td>\n",
       "      <td>S</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   PassengerId  Pclass                                               Name  \\\n",
       "0          710       3  Moubarek, Master. Halim Gonios (\"William George\")   \n",
       "1          440       2             Kvillner, Mr. Johan Henrik Johannesson   \n",
       "2          841       3                        Alhomaki, Mr. Ilmari Rudolf   \n",
       "\n",
       "    Sex   Age  SibSp  Parch            Ticket     Fare Cabin Embarked  \n",
       "0  male   NaN      1      1              2661  15.2458   NaN        C  \n",
       "1  male  31.0      0      0        C.A. 18723  10.5000   NaN        S  \n",
       "2  male  20.0      0      0  SOTON/O2 3101287   7.9250   NaN        S  "
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X_test = pd.read_csv(\"X_test.csv\")\n",
    "y_test = pd.read_csv(\"y_test.csv\")\n",
    "X_test.head(3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "with open('logreg_pipeline.dill', 'rb') as in_strm:\n",
    "    pipeline = dill.load(in_strm)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([1, 0], dtype=int64)"
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y_test['Survived'].unique()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "preds = pipeline.predict_proba(X_test)[:, 1]\n",
    "\n",
    "pred_df = pd.DataFrame({'preds': preds})\n",
    "pred_df.to_csv(\"test_predictions.csv\", index=None)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([0.11294452, 0.20338122, 0.12611295, 0.85733642, 0.74829539,\n",
       "       0.91272715, 0.61800209, 0.0874193 , 0.731411  , 0.90059009])"
      ]
     },
     "execution_count": 22,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "preds[:10]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Best Threshold=0.33721850606237047, F-Score=0.794, Precision=0.745, Recall=0.850\n"
     ]
    }
   ],
   "source": [
    "precision, recall, thresholds = precision_recall_curve(y_test, preds)\n",
    "\n",
    "fscore = (2 * precision * recall) / (precision + recall)\n",
    "ix = np.argmax(fscore)\n",
    "\n",
    "print(f'Best Threshold={thresholds[ix]}, F-Score={fscore[ix]:.3f}, Precision={precision[ix]:.3f}, Recall={recall[ix]:.3f}')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Step 3 - FLASK"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: flask-ngrok in c:\\users\\kvmar\\anaconda3\\lib\\site-packages (0.0.25)\n",
      "Requirement already satisfied: requests in c:\\users\\kvmar\\anaconda3\\lib\\site-packages (from flask-ngrok) (2.25.1)\n",
      "Requirement already satisfied: Flask>=0.8 in c:\\users\\kvmar\\anaconda3\\lib\\site-packages (from flask-ngrok) (1.1.2)\n",
      "Requirement already satisfied: Werkzeug>=0.15 in c:\\users\\kvmar\\anaconda3\\lib\\site-packages (from Flask>=0.8->flask-ngrok) (1.0.1)\n",
      "Requirement already satisfied: Jinja2>=2.10.1 in c:\\users\\kvmar\\anaconda3\\lib\\site-packages (from Flask>=0.8->flask-ngrok) (2.11.3)\n",
      "Requirement already satisfied: click>=5.1 in c:\\users\\kvmar\\anaconda3\\lib\\site-packages (from Flask>=0.8->flask-ngrok) (7.1.2)\n",
      "Requirement already satisfied: itsdangerous>=0.24 in c:\\users\\kvmar\\anaconda3\\lib\\site-packages (from Flask>=0.8->flask-ngrok) (1.1.0)\n",
      "Requirement already satisfied: MarkupSafe>=0.23 in c:\\users\\kvmar\\anaconda3\\lib\\site-packages (from Jinja2>=2.10.1->Flask>=0.8->flask-ngrok) (1.1.1)\n",
      "Requirement already satisfied: certifi>=2017.4.17 in c:\\users\\kvmar\\anaconda3\\lib\\site-packages (from requests->flask-ngrok) (2020.12.5)\n",
      "Requirement already satisfied: idna<3,>=2.5 in c:\\users\\kvmar\\anaconda3\\lib\\site-packages (from requests->flask-ngrok) (2.10)\n",
      "Requirement already satisfied: urllib3<1.27,>=1.21.1 in c:\\users\\kvmar\\anaconda3\\lib\\site-packages (from requests->flask-ngrok) (1.26.4)\n",
      "Requirement already satisfied: chardet<5,>=3.0.2 in c:\\users\\kvmar\\anaconda3\\lib\\site-packages (from requests->flask-ngrok) (4.0.0)\n"
     ]
    }
   ],
   "source": [
    "!pip install flask-ngrok"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [],
   "source": [
    "from flask_ngrok import run_with_ngrok\n",
    "from flask import Flask, request, jsonify\n",
    "import pandas as pd"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\"wget\" ­Ґ пў«пҐвбп ў­гваҐ­­Ґ© Ё«Ё ў­Ґи­Ґ©\n",
      "Є®¬ ­¤®©, ЁбЇ®«­пҐ¬®© Їа®Ја ¬¬®© Ё«Ё Ї ЄҐв­л¬ д ©«®¬.\n",
      "tar: Error opening archive: Failed to open '/content/ngrok-stable-linux-amd64.tgz'\n",
      "\".\" ­Ґ пў«пҐвбп ў­гваҐ­­Ґ© Ё«Ё ў­Ґи­Ґ©\n",
      "Є®¬ ­¤®©, ЁбЇ®«­пҐ¬®© Їа®Ја ¬¬®© Ё«Ё Ї ЄҐв­л¬ д ©«®¬.\n",
      "\".\" ­Ґ пў«пҐвбп ў­гваҐ­­Ґ© Ё«Ё ў­Ґи­Ґ©\n",
      "Є®¬ ­¤®©, ЁбЇ®«­пҐ¬®© Їа®Ја ¬¬®© Ё«Ё Ї ЄҐв­л¬ д ©«®¬.\n"
     ]
    }
   ],
   "source": [
    "!wget https://bin.equinox.io/c/4VmDzA7iaHb/ngrok-stable-linux-amd64.tgz\n",
    "!tar -xvf /content/ngrok-stable-linux-amd64.tgz\n",
    "!./ngrok authtoken 25vEpcJ5Ih4vlUp4thEZ9sEA6ZU_3Bnu17gKacRXhF6hLeefc\n",
    "!./ngrok http 80"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " * Serving Flask app \"__main__\" (lazy loading)\n",
      " * Environment: production\n",
      "   WARNING: This is a development server. Do not use it in a production deployment.\n",
      "   Use a production WSGI server instead.\n",
      " * Debug mode: off\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " * Running on http://127.0.0.1:5000/ (Press CTRL+C to quit)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " * Running on http://87b7-178-141-108-237.ngrok.io\n",
      " * Traffic stats available on http://127.0.0.1:4040\n"
     ]
    }
   ],
   "source": [
    "# Пробный запуск Flask\n",
    "\n",
    "app = Flask(__name__)\n",
    "run_with_ngrok(app)  # Start ngrok when app is run\n",
    "\n",
    "@app.route(\"/a\")\n",
    "def hello():\n",
    "    return \"Hello World!\"\n",
    "\n",
    "if __name__ == '__main__':\n",
    "    app.run()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
